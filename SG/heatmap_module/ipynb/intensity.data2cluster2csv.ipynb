{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load the necessary libraries\n",
    "'''\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import *\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "sns.set_color_codes()\n",
    "plot_kwds = {'alpha' : 0.5, 's' : 80, 'linewidths':0}\n",
    "\n",
    "import hdbscan\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import pairwise_distances_argmin_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cluster_nuclei(filename,sample_size,n_neighbors,threshold_q,min_cluster_size,min_samples):\n",
    "def cluster_nuclei(filename,sample_size,n_neighbors,threshold_q,auto_open):\n",
    "    df = pd.read_pickle(filename)\n",
    "    if sample_size > 0 and sample_size < df.shape[0]:\n",
    "        df = df.sample(n=sample_size)\n",
    "    embedding = df[['x','y','z']].to_numpy()\n",
    "    \n",
    "    '''\n",
    "    Calculate the local curvature of the point cloud embedding\n",
    "    '''\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='kd_tree').fit(embedding)\n",
    "    distances, indices = nbrs.kneighbors(embedding)\n",
    "    eigvals = [LA.eigvalsh(np.cov(embedding[indices[idx,:],:].T)) for idx in range(embedding.shape[0])] #full data\n",
    "\n",
    "    curvatures = [min(eigvals[idx])/sum(eigvals[idx]) for idx in range(len(eigvals))]\n",
    "\n",
    "    # Add curvature to the dataframe\n",
    "    df['curvature'] = curvatures \n",
    "\n",
    "    # Find the minima in curvature histrogram\n",
    "    q1 = np.quantile(curvatures,threshold_q)\n",
    "\n",
    "    df1 = df[df['curvature'] <= q1] # define the low curvature sector\n",
    "\n",
    "    min_cluster_size = round(df1.shape[0]/15) # parameter to be adjausted\n",
    "    min_samples = round(min_cluster_size/15)       # parameter to be adjausted\n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(min_samples=min_samples,min_cluster_size=min_cluster_size,gen_min_span_tree=True)\n",
    "    clusterer.fit(df1.loc[:,('x','y','z')]) \n",
    "\n",
    "    clusterer.condensed_tree_.plot(select_clusters=True,\n",
    "                                   selection_palette=sns.color_palette(\"Set2\",len(clusterer.labels_)))\n",
    "    plt.savefig(filename+'.tree.png')\n",
    "    plt.close()\n",
    "    \n",
    "    df1['cluster'] = clusterer.labels_    # add cluster id to dataframe\n",
    "    df1['cluster'] = df1['cluster'].apply(str)   # make cluster id a string\n",
    "    df1_filtered = df1[df1.cluster != str(-1)] # remove unassigned points\n",
    "\n",
    "    # expand the clusters to the entire point-cloud\n",
    "    idx, dist = pairwise_distances_argmin_min(df[['x','y','z']].to_numpy(),df1_filtered[['x','y','z']].to_numpy())\n",
    "    df['cluster'] = [int(df1_filtered.cluster.iloc[idx[row]])+1 for row in range(df.shape[0])] #add 1 to avoid confusion with background\n",
    "    df.to_csv(filename+'.csv',index=False)\n",
    "    \n",
    "    fig = px.scatter(df1_filtered, x=\"cx\", y=\"cy\",color=\"cluster\",\n",
    "                         width=800, height=800,\n",
    "                         color_discrete_sequence=px.colors.qualitative.Set2)\n",
    "    fig.update_traces(marker=dict(size=5,opacity=1.0))\n",
    "    fig.write_html(filename+'.spatial_decoration.html', auto_open=auto_open)\n",
    "    fig.write_image(filename+'.spatial_decoration.png')\n",
    "\n",
    "    fig = px.scatter_3d(df1_filtered, x=\"x\", y=\"y\", z=\"z\", color=\"cluster\", hover_name=\"cluster\", \n",
    "                            color_discrete_sequence=px.colors.qualitative.Set2)\n",
    "    fig.update_traces(marker=dict(size=3,opacity=0.75),selector=dict(mode='markers'))\n",
    "    fig.write_html(filename+'.low_curvature_clusters.html', auto_open=auto_open)\n",
    "    fig.write_image(filename+'.low_curvature_clusters.png')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cluster_nuclei(filename,sample_size,n_neighbors,threshold_q,min_cluster_size,min_samples):\n",
    "def cluster_nuclei(filename,sample_size,n_neighbors,threshold_q,auto_open):\n",
    "    df = pd.read_pickle(filename)\n",
    "    if sample_size > 0 and sample_size < df.shape[0]:\n",
    "        df = df.sample(n=sample_size)\n",
    "    embedding = df[['x','y','z']].to_numpy()\n",
    "    \n",
    "    '''\n",
    "    Calculate the local curvature of the point cloud embedding\n",
    "    '''\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm='kd_tree').fit(embedding)\n",
    "    distances, indices = nbrs.kneighbors(embedding)\n",
    "    eigvals = [LA.eigvalsh(np.cov(embedding[indices[idx,:],:].T)) for idx in range(embedding.shape[0])] #full data\n",
    "\n",
    "    curvatures = [min(eigvals[idx])/sum(eigvals[idx]) for idx in range(len(eigvals))]\n",
    "\n",
    "    # Add curvature to the dataframe\n",
    "    df['curvature'] = curvatures \n",
    "\n",
    "    # Find the minima in curvature histrogram\n",
    "    q1 = np.quantile(curvatures,threshold_q)\n",
    "\n",
    "    df1 = df[df['curvature'] <= q1] # define the low curvature sector\n",
    "\n",
    "    min_cluster_size = round(df1.shape[0]/15) # parameter to be adjausted\n",
    "    min_samples = round(min_cluster_size/15)       # parameter to be adjausted\n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(min_samples=min_samples,min_cluster_size=min_cluster_size,gen_min_span_tree=True)\n",
    "    clusterer.fit(df1.loc[:,('x','y','z')]) \n",
    "\n",
    "    clusterer.condensed_tree_.plot(select_clusters=True,\n",
    "                                   selection_palette=sns.color_palette(\"Set2\",len(clusterer.labels_)))\n",
    "    plt.savefig(filename+'.tree.png')\n",
    "    plt.close()\n",
    "    df1['cluster'] = clusterer.labels_    # add cluster id to dataframe\n",
    "    df1['cluster'] = df1['cluster'].apply(str)   # make cluster id a string\n",
    "    df1_filtered = df1[df1.cluster != str(-1)] # remove unassigned points\n",
    "    \n",
    "    # expand the clusters to the entire point-cloud\n",
    "    idx, dist = pairwise_distances_argmin_min(df[['x','y','z']].to_numpy(),df1_filtered[['x','y','z']].to_numpy())\n",
    "    df['cluster'] = [int(df1_filtered.cluster.iloc[idx[row]])+1 for row in range(df.shape[0])] #add 1 to avoid confusion with background\n",
    "    df.to_csv(filename+'.csv',index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garner1/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/home/garner1/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_size = 0\n",
    "n_neighbors = 100\n",
    "threshold_q = 0.1\n",
    "auto_open = True\n",
    "#min_cluster_size = 1000\n",
    "#min_samples = 500\n",
    "\n",
    "for filename in glob.glob(r'../pkl/id_13.*.pkl'):\n",
    "    #df_out = cluster_nuclei(filename,sample_size,n_neighbors,threshold_q,min_cluster_size,min_samples)\n",
    "    df_out = cluster_nuclei(filename,sample_size,n_neighbors,threshold_q,auto_open=auto_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504854, 14)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
