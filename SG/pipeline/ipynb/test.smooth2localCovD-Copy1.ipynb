{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import *\n",
    "import plotly.express as px\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "import umap\n",
    "from graviti import *\n",
    "import networkx as nx\n",
    "from scipy import sparse, linalg\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '/home/garner1/Work/pipelines/WSI-analysis/SG/pipeline/data/id_52'  #sys.argv[1] # the directory where features.npz files are located\n",
    "sample = '52' #sys.argv[2]  # the sample id\n",
    "\n",
    "counter = 0\n",
    "for f in glob.glob(dirname+'/*features.npz'): # for every fov\n",
    "    counter += 1\n",
    "    if counter == 1:            # set up the data arrays\n",
    "        data = np.load(f,allow_pickle=True)\n",
    "        fov = data['fov']\n",
    "        xy = data['centroids']\n",
    "        morphology = data['morphology']\n",
    "    else:                       # update the data arrays\n",
    "        data = np.load(f,allow_pickle=True)\n",
    "        fov = np.vstack((fov,data['fov']))\n",
    "        xy = np.vstack((xy, data['centroids']))\n",
    "        morphology = np.vstack((morphology, data['morphology']))\n",
    "\n",
    "# Create dataframes\n",
    "df_fov = pd.DataFrame(data=fov, columns=['fov_row','fov_col'])\n",
    "df_xy = pd.DataFrame(data=xy, columns=['cx','cy'])\n",
    "df_morphology = pd.DataFrame(data=morphology, columns=['area','perimeter','solidity','eccentricity','circularity','mean_intensity','std_intensity'])\n",
    "\n",
    "# Concatenate all dataframes\n",
    "df = pd.concat([df_fov,df_xy, df_morphology],axis=1)\n",
    "\n",
    "# filter by percentiles in morphologies (hardcoded in function filtering)\n",
    "fdf = filtering(df) # .sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fov_row', 'fov_col', 'cx', 'cy', 'area', 'perimeter', 'solidity',\n",
       "       'eccentricity', 'circularity', 'mean_intensity', 'std_intensity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the UMAP graph\n",
      "The graph already exists\n",
      "The network already exists\n"
     ]
    }
   ],
   "source": [
    "# Get the positions of centroids \n",
    "pos = fdf[fdf.columns[2:4]].to_numpy()\n",
    "nn = 10 # number of nearest neighbor in umap\n",
    "print('Building the UMAP graph')\n",
    "filename = '../py/'+str(sample)+'.graph.npz' # the adj sparse matrix\n",
    "if path.exists(filename):\n",
    "    print('The graph already exists')\n",
    "    A = sparse.load_npz(filename) \n",
    "else:\n",
    "    print('Creating the graph')\n",
    "    A = space2graph(pos,nn)\n",
    "    sparse.save_npz(filename, A)\n",
    "    \n",
    "filename = '../py/'+str(sample)+'.graph.pickle'    # the networkx obj\n",
    "if path.exists(filename):    \n",
    "    print('The network already exists')\n",
    "    G = nx.read_gpickle(filename)\n",
    "else:\n",
    "    print('Creating the network')\n",
    "    G = nx.from_scipy_sparse_matrix(A, edge_attribute='weight')\n",
    "    nx.write_gpickle(G, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm(A,times):\n",
    "    if times > 0:\n",
    "        M = A.dot(A)\n",
    "    for t in range(1,times):\n",
    "        newM = A.dot(M)\n",
    "        M = newM\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed_covd(A,fdf,r):\n",
    "    M = mm(A,r)\n",
    "    row_idx, col_idx = M.nonzero()\n",
    "    descriptor = np.zeros((A.shape[0],28))\n",
    "    for row_ID in range(A.shape[0]):\n",
    "        mask = row_idx == row_ID # the non-zero elements idx at row rowID\n",
    "        a = M[row_ID,col_idx[mask]] # the non-zero elements entries at row rowID\n",
    "        morphology = fdf.iloc[mask][['area','perimeter','solidity','eccentricity','circularity','mean_intensity','cov_intensity']].to_numpy()\n",
    "        C = np.cov(morphology,rowvar=False,aweights=a.data) # the covd for row_ID weighted with paths\n",
    "        iu1 = np.triu_indices(C.shape[1]) # the indices of the upper triangular part\n",
    "        covd2vec = C[iu1]\n",
    "        descriptor[row_ID,:] = covd2vec\n",
    "    return descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = smoothed_covd(A,fdf,1)\n",
    "descriptor[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_smoothing(W,data,radius):\n",
    "    S = normalize(W, norm='l1', axis=1) #create the row-stochastic matrix\n",
    "\n",
    "    smooth = np.zeros((data.shape[0],data.shape[1]))\n",
    "    summa = data\n",
    "    for counter in range(radius):\n",
    "        newdata = S.dot(data)\n",
    "        data = newdata\n",
    "        if counter == radius-1:\n",
    "            smooth = summa*1.0/(counter+1)\n",
    "    return smooth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Smooth the morphology')\n",
    "radius = 10000\n",
    "data = fdf[fdf.columns[4:]].to_numpy()\n",
    "smooth_data = smoothing(A,data,radius)\n",
    "new_fdf = pd.DataFrame(data=smooth_data,columns=fdf.columns[4:],index=fdf.index)\n",
    "df = pd.concat([fdf[fdf.columns[:4]],new_fdf],axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
