{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import *\n",
    "import plotly.express as px\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "import umap\n",
    "from graviti import *\n",
    "import networkx as nx\n",
    "from scipy import sparse, linalg\n",
    "import pickle\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covd_local(r,A,data,row_idx,col_idx):\n",
    "    mask = row_idx == r         # find nearest neigthbors\n",
    "    cluster = np.append(r,col_idx[mask]) # define the local cluster, its size depends on the local connectivity\n",
    "    a = A[r,cluster]\n",
    "    a = np.hstack(([1],a.data))\n",
    "    d = data[cluster,:]\n",
    "    C = np.cov(d,rowvar=False,aweights=a)\n",
    "    iu1 = np.triu_indices(C.shape[1])\n",
    "    vec = C[iu1]\n",
    "    return (r,vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '../h5/id_52/' # the path to *features.npz files \n",
    "sample = '52' #sys.argv[2]  # the sample id\n",
    "size = 100000 # number of nuclei, use negative value for full set\n",
    "nn = 10 # set the number of nearest neighbor in the umap-graph. Will be used in CovD as well\n",
    "N = int(np.sqrt(size)/10) # number of linear bins for the contour visualization\n",
    "print('N: ',str(N))\n",
    "\n",
    "features = ['area',\n",
    "            'perimeter',\n",
    "            'solidity',\n",
    "            'eccentricity',\n",
    "            'circularity',\n",
    "            'mean_intensity',\n",
    "            'std_intensity',\n",
    "            'cov_intensity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for f in glob.glob(dirname+'/*features.npz'): # for every fov\n",
    "    counter += 1\n",
    "    if counter == 1:            # set up the data arrays\n",
    "        data = np.load(f,allow_pickle=True)\n",
    "        fov = data['fov']\n",
    "        xy = data['centroids']\n",
    "        morphology = data['morphology']\n",
    "    else:                       # update the data arrays\n",
    "        data = np.load(f,allow_pickle=True)\n",
    "        fov = np.vstack((fov,data['fov']))\n",
    "        xy = np.vstack((xy, data['centroids']))\n",
    "        morphology = np.vstack((morphology, data['morphology']))\n",
    "\n",
    "# Create dataframes with spatial and morphological measurements\n",
    "df_fov = pd.DataFrame(data=fov, columns=['fov_row','fov_col']) # field of view dataframe\n",
    "df_xy = pd.DataFrame(data=xy, columns=['cx','cy'])   # centroid dataframe\n",
    "df_morphology = pd.DataFrame(data=morphology, columns=['area','perimeter','solidity','eccentricity','circularity','mean_intensity','std_intensity'])\n",
    "\n",
    "# Concatenate spatial and morphological dataframes\n",
    "df = pd.concat([df_fov,df_xy, df_morphology],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by percentiles in morphologies (hardcoded in function filtering) and introduce coeff. of var\n",
    "if size < 0:\n",
    "    fdf = filtering(df) # filter out extremes in morphology\n",
    "else:\n",
    "    fdf = filtering(df).sample(n=size) # filter out morphological outlyers and subsample nuclei\n",
    "\n",
    "pos = fdf[fdf.columns[2:4]].to_numpy() # Get the positions of centroids \n",
    "\n",
    "# Building the UMAP graph\n",
    "filename = '../py/ID'+str(sample)+'.size'+str(size)+'.nn'+str(nn)+'.graph.npz' # the adj sparse matrix\n",
    "if path.exists(filename):\n",
    "    print('The graph already exists')\n",
    "    A = sparse.load_npz(filename) \n",
    "else:\n",
    "    print('Creating the graph')\n",
    "    A = space2graph(pos,nn)\n",
    "    sparse.save_npz(filename, A)\n",
    "    \n",
    "filename = '../py/ID'+str(sample)+'.size'+str(size)+'.nn'+str(nn)+'.graph.pickle'    # the networkx obj\n",
    "if path.exists(filename):    \n",
    "    print('The network already exists')\n",
    "    G = nx.read_gpickle(filename)\n",
    "else:\n",
    "    print('Creating the network')\n",
    "    G = nx.from_scipy_sparse_matrix(A, edge_attribute='weight')\n",
    "    nx.write_gpickle(G, filename)\n",
    "\n",
    "data = fdf[features].to_numpy() #get the morphological data\n",
    "\n",
    "# Parallel generation of the local covd\n",
    "filename = '../py/ID'+str(sample)+'.size'+str(size)+'.nn'+str(nn)+'.descriptor.pickle'    # the descriptor\n",
    "if path.exists(filename):    \n",
    "    print('The descriptor already exists')\n",
    "    descriptor = pickle.load( open( filename, \"rb\" ) )\n",
    "else:\n",
    "    print('Generating the descriptor')\n",
    "    num_cores = multiprocessing.cpu_count() # numb of cores\n",
    "    row_idx, col_idx = A.nonzero() # nonzero entries\n",
    "    processed_list = Parallel(n_jobs=num_cores)(delayed(covd_local)(r,A,data,row_idx,col_idx) \n",
    "                                                            for r in range(A.shape[0])\n",
    "                                                   )\n",
    "\n",
    "    # Construct the descriptor array\n",
    "    descriptor = np.zeros((len(processed_list),processed_list[0][1].shape[0]))\n",
    "    for r in range(len(processed_list)):\n",
    "        descriptor[r,:] = processed_list[r][1] # covd descriptors of the connected nodes\n",
    "    pickle.dump( descriptor, open( filename, \"wb\" ) )\n",
    "    \n",
    "# Construct the local Laplacian\n",
    "L = nx.laplacian_matrix(G, weight='weight') # get the Laplacian matrix\n",
    "delta_descriptor = L.dot(descriptor) # get the local differianted descriptor\n",
    "delta = norm(delta_descriptor,axis=1) # get the norm of the differential field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour visualization\n",
    "fdf['field'] = delta # define the laplacian field\n",
    "fdf['x_bin'] = pd.cut(fdf['cx'], N, labels=False) # define the x bin label\n",
    "fdf['y_bin'] = pd.cut(fdf['cy'], N, labels=False) # define the y bin label\n",
    "\n",
    "# define the pivot tabel for the contour plot\n",
    "table = pd.pivot_table(fdf, \n",
    "                       values='field', \n",
    "                       index=['x_bin'],\n",
    "                       columns=['y_bin'],\n",
    "                       aggfunc=np.median, # take the mean of the entries in the bin\n",
    "                       fill_value=None)\n",
    "\n",
    "X=table.columns.values\n",
    "Y=table.index.values\n",
    "Z=table.values\n",
    "Xi,Yi = np.meshgrid(X, Y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cs = ax.contourf(Yi, Xi, Z, \n",
    "                 alpha=1.0, \n",
    "                 levels=10,\n",
    "                 cmap=plt.cm.viridis);\n",
    "cbar = fig.colorbar(cs)\n",
    "plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
